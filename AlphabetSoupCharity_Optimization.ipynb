{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTi3hoqiJkIf"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7J62w_T4JkIh"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization Attempt 1: Dropping more columns"
      ],
      "metadata": {
        "id": "HracvgcowG-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Import and read the charity_data.csv.\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()\n",
        "\n",
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop(['EIN', 'NAME', 'ASK_AMT'], axis=1)\n",
        "\n",
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()\n",
        "\n",
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "application_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
        "application_counts\n",
        "\n",
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "cutoff_value = 100\n",
        "application_types_to_replace = list(application_counts[application_counts < cutoff_value].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n",
        "\n",
        "# Look at CLASSIFICATION value counts for binning\n",
        "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "classification_counts\n",
        "\n",
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "classification_counts[classification_counts > 1]\n",
        "\n",
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "cutoff_value = 1000\n",
        "classifications_to_replace = list(classification_counts[classification_counts < cutoff_value].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()\n",
        "\n",
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "categorical_columns = ['APPLICATION_TYPE', 'AFFILIATION', 'USE_CASE', 'ORGANIZATION', 'INCOME_AMT', 'SPECIAL_CONSIDERATIONS', 'CLASSIFICATION']\n",
        "application_df = pd.get_dummies(application_df, columns=categorical_columns)\n",
        "\n",
        "# Split our preprocessed data into our features and target arrays\n",
        "X = application_df.drop(columns=['IS_SUCCESSFUL'])\n",
        "y = application_df['IS_SUCCESSFUL']\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
        "\n",
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "\n",
        "#--------------------------------------\n",
        "# Compile, Train and Evaluate the Model\n",
        "\n",
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "#  YOUR CODE GOES HERE\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=80, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "# Train the model\n",
        "nn.fit(X_train_scaled, y_train, epochs=100)\n",
        "\n",
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awaYLb3jwgwx",
        "outputId": "4ef8f7a0-8e19-408f-8148-654079ef24ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_23 (Dense)            (None, 80)                3520      \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 30)                2430      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,981\n",
            "Trainable params: 5,981\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5689 - accuracy: 0.7211\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5542 - accuracy: 0.7300\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5509 - accuracy: 0.7302\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5502 - accuracy: 0.7318\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5491 - accuracy: 0.7326\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5478 - accuracy: 0.7313\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.7319\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7335\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.7335\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.7342\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7339\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7345\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5447 - accuracy: 0.7355\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5445 - accuracy: 0.7351\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7344\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7355\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5434 - accuracy: 0.7348\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.7356\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7362\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7354\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7369\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7364\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7358\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7369\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7367\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7374\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5412 - accuracy: 0.7374\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7378\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7374\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5403 - accuracy: 0.7385\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7377\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7378\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5397 - accuracy: 0.7370\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7378\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7388\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5390 - accuracy: 0.7384\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.7375\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5389 - accuracy: 0.7385\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7381\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7386\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7375\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7386\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7381\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5382 - accuracy: 0.7380\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5382 - accuracy: 0.7388\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5383 - accuracy: 0.7395\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.7389\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7375\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.7393\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7390\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.7377\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.7387\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7393\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5375 - accuracy: 0.7390\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7395\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.7393\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7389\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7390\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.7394\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7392\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7390\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5368 - accuracy: 0.7390\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7387\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7390\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7390\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7386\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7386\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7396\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7395\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5366 - accuracy: 0.7394\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7393\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7390\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7385\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7399\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7393\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7390\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7397\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5356 - accuracy: 0.7388\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7386\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5359 - accuracy: 0.7383\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7393\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7399\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7395\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7392\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7392\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5354 - accuracy: 0.7393\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7399\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7406\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7400\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7397\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7399\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7399\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7397\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5354 - accuracy: 0.7400\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7402\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7400\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7403\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7402\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7397\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7391\n",
            "268/268 - 0s - loss: 0.5556 - accuracy: 0.7300 - 461ms/epoch - 2ms/step\n",
            "Loss: 0.5556338429450989, Accuracy: 0.7300291657447815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization Attempt 2: Creating more bins for rare occurrences in columns"
      ],
      "metadata": {
        "id": "BQl2xdA9y0T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Import and read the charity_data.csv.\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()\n",
        "\n",
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop(['EIN', 'NAME'], axis=1)\n",
        "\n",
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()\n",
        "\n",
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "application_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
        "application_counts\n",
        "\n",
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "cutoff_value = 100\n",
        "application_types_to_replace = list(application_counts[application_counts < cutoff_value].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n",
        "\n",
        "# Look at CLASSIFICATION value counts for binning\n",
        "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "classification_counts\n",
        "\n",
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "classification_counts[classification_counts > 1]\n",
        "\n",
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "cutoff_value = 1000\n",
        "classifications_to_replace = list(classification_counts[classification_counts < cutoff_value].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Create more bins for rare occurrences in the 'ASK_AMT' column\n",
        "bin_edges = [0, 1000, 5000, 10000, 50000, 100000, 500000, 1000000]\n",
        "application_df['ASK_AMT'] = pd.cut(application_df['ASK_AMT'], bins=bin_edges)\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()\n",
        "\n",
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "categorical_columns = ['APPLICATION_TYPE', 'AFFILIATION', 'USE_CASE', 'ORGANIZATION', 'INCOME_AMT', 'SPECIAL_CONSIDERATIONS', 'CLASSIFICATION','ASK_AMT']\n",
        "application_df = pd.get_dummies(application_df, columns=categorical_columns)\n",
        "\n",
        "# Split our preprocessed data into our features and target arrays\n",
        "X = application_df.drop(columns=['IS_SUCCESSFUL'])\n",
        "y = application_df['IS_SUCCESSFUL']\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
        "\n",
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "\n",
        "#--------------------------------------\n",
        "# Compile, Train and Evaluate the Model\n",
        "\n",
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "#  YOUR CODE GOES HERE\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=80, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "# Train the model\n",
        "nn.fit(X_train_scaled, y_train, epochs=100)\n",
        "\n",
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tpn1NDVR0YVO",
        "outputId": "cae9e47a-564a-4a79-fd4c-388c2004caec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 80)                4080      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 30)                2430      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,541\n",
            "Trainable params: 6,541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5708 - accuracy: 0.7189\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5554 - accuracy: 0.7287\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5513 - accuracy: 0.7299\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7317\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.7332\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7336\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7332\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5448 - accuracy: 0.7351\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7345\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5419 - accuracy: 0.7354\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7366\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5414 - accuracy: 0.7345\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5404 - accuracy: 0.7375\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5402 - accuracy: 0.7341\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5397 - accuracy: 0.7381\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7380\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5386 - accuracy: 0.7386\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5386 - accuracy: 0.7383\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7373\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5371 - accuracy: 0.7384\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7386\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7395\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5361 - accuracy: 0.7388\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5354 - accuracy: 0.7393\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7406\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7385\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.7393\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7402\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7403\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.7408\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7407\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5335 - accuracy: 0.7406\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7397\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5323 - accuracy: 0.7411\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5326 - accuracy: 0.7419\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.7423\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.7414\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7411\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7418\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5313 - accuracy: 0.7421\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5314 - accuracy: 0.7407\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5311 - accuracy: 0.7419\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5309 - accuracy: 0.7422\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7408\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.7426\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5305 - accuracy: 0.7416\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5300 - accuracy: 0.7419\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7431\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5303 - accuracy: 0.7410\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7421\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7424\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5298 - accuracy: 0.7415\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5292 - accuracy: 0.7424\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.7431\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5294 - accuracy: 0.7409\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5286 - accuracy: 0.7433\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5289 - accuracy: 0.7407\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5281 - accuracy: 0.7432\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5286 - accuracy: 0.7422\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5286 - accuracy: 0.7430\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5284 - accuracy: 0.7430\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5285 - accuracy: 0.7434\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5279 - accuracy: 0.7418\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5279 - accuracy: 0.7430\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5278 - accuracy: 0.7434\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5275 - accuracy: 0.7433\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5276 - accuracy: 0.7428\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5274 - accuracy: 0.7441\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5271 - accuracy: 0.7429\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5278 - accuracy: 0.7434\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 4s 6ms/step - loss: 0.5279 - accuracy: 0.7426\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5270 - accuracy: 0.7432\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5272 - accuracy: 0.7429\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5270 - accuracy: 0.7426\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5272 - accuracy: 0.7427\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5269 - accuracy: 0.7451\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5262 - accuracy: 0.7446\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5266 - accuracy: 0.7443\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5268 - accuracy: 0.7432\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5263 - accuracy: 0.7430\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5262 - accuracy: 0.7443\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5268 - accuracy: 0.7434\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5261 - accuracy: 0.7421\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5261 - accuracy: 0.7425\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5262 - accuracy: 0.7442\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5258 - accuracy: 0.7436\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5257 - accuracy: 0.7435\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5258 - accuracy: 0.7441\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5257 - accuracy: 0.7441\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5259 - accuracy: 0.7441\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5258 - accuracy: 0.7444\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5255 - accuracy: 0.7446\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5257 - accuracy: 0.7442\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5255 - accuracy: 0.7442\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5253 - accuracy: 0.7439\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5257 - accuracy: 0.7431\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5250 - accuracy: 0.7434\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5249 - accuracy: 0.7445\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5256 - accuracy: 0.7428\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5251 - accuracy: 0.7432\n",
            "268/268 - 0s - loss: 0.5602 - accuracy: 0.7276 - 486ms/epoch - 2ms/step\n",
            "Loss: 0.5602007508277893, Accuracy: 0.727580189704895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization Attempt 3: More Hidden Layers, Neurons & Activation Functions"
      ],
      "metadata": {
        "id": "u7TAk0lTyyLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Import and read the charity_data.csv.\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()\n",
        "\n",
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop(['EIN', 'NAME', 'ASK_AMT'], axis=1)\n",
        "\n",
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()\n",
        "\n",
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "application_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
        "application_counts\n",
        "\n",
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "cutoff_value = 100\n",
        "application_types_to_replace = list(application_counts[application_counts < cutoff_value].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n",
        "\n",
        "# Look at CLASSIFICATION value counts for binning\n",
        "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "classification_counts\n",
        "\n",
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "classification_counts[classification_counts > 1]\n",
        "\n",
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "cutoff_value = 1000\n",
        "classifications_to_replace = list(classification_counts[classification_counts < cutoff_value].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()\n",
        "\n",
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "categorical_columns = ['APPLICATION_TYPE', 'AFFILIATION', 'USE_CASE', 'ORGANIZATION', 'INCOME_AMT', 'SPECIAL_CONSIDERATIONS', 'CLASSIFICATION']\n",
        "application_df = pd.get_dummies(application_df, columns=categorical_columns)\n",
        "\n",
        "# Split our preprocessed data into our features and target arrays\n",
        "X = application_df.drop(columns=['IS_SUCCESSFUL'])\n",
        "y = application_df['IS_SUCCESSFUL']\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
        "\n",
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "\n",
        "#--------------------------------------\n",
        "# Compile, Train and Evaluate the Model\n",
        "\n",
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "#  YOUR CODE GOES HERE\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer: ADDING MORE NEURONS AND CHANGIG FUNCTIONS\n",
        "nn.add(tf.keras.layers.Dense(units=200, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
        "\n",
        "# Second hidden layer: ADDING MORE LAYERS AND ACTIVATION FUNCTIONS\n",
        "nn.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
        "nn.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
        "nn.add(tf.keras.layers.Dense(units=50, activation='tanh'))\n",
        "nn.add(tf.keras.layers.Dense(units=50, activation='tanh'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "# Train the model\n",
        "nn.fit(X_train_scaled, y_train, epochs=50,verbose=2)\n",
        "\n",
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izctqt2Xyxxq",
        "outputId": "37f9c2cf-4e70-4aca-b333-413c890c8e75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 200)               8800      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 50)                10050     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,551\n",
            "Trainable params: 26,551\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "804/804 - 3s - loss: 0.5674 - accuracy: 0.7210 - 3s/epoch - 3ms/step\n",
            "Epoch 2/50\n",
            "804/804 - 2s - loss: 0.5561 - accuracy: 0.7286 - 2s/epoch - 2ms/step\n",
            "Epoch 3/50\n",
            "804/804 - 2s - loss: 0.5534 - accuracy: 0.7329 - 2s/epoch - 2ms/step\n",
            "Epoch 4/50\n",
            "804/804 - 2s - loss: 0.5516 - accuracy: 0.7311 - 2s/epoch - 2ms/step\n",
            "Epoch 5/50\n",
            "804/804 - 3s - loss: 0.5506 - accuracy: 0.7317 - 3s/epoch - 3ms/step\n",
            "Epoch 6/50\n",
            "804/804 - 2s - loss: 0.5484 - accuracy: 0.7331 - 2s/epoch - 2ms/step\n",
            "Epoch 7/50\n",
            "804/804 - 2s - loss: 0.5484 - accuracy: 0.7345 - 2s/epoch - 2ms/step\n",
            "Epoch 8/50\n",
            "804/804 - 2s - loss: 0.5481 - accuracy: 0.7341 - 2s/epoch - 2ms/step\n",
            "Epoch 9/50\n",
            "804/804 - 2s - loss: 0.5474 - accuracy: 0.7347 - 2s/epoch - 2ms/step\n",
            "Epoch 10/50\n",
            "804/804 - 2s - loss: 0.5464 - accuracy: 0.7337 - 2s/epoch - 2ms/step\n",
            "Epoch 11/50\n",
            "804/804 - 2s - loss: 0.5460 - accuracy: 0.7349 - 2s/epoch - 2ms/step\n",
            "Epoch 12/50\n",
            "804/804 - 2s - loss: 0.5459 - accuracy: 0.7344 - 2s/epoch - 3ms/step\n",
            "Epoch 13/50\n",
            "804/804 - 2s - loss: 0.5452 - accuracy: 0.7364 - 2s/epoch - 2ms/step\n",
            "Epoch 14/50\n",
            "804/804 - 2s - loss: 0.5446 - accuracy: 0.7352 - 2s/epoch - 2ms/step\n",
            "Epoch 15/50\n",
            "804/804 - 2s - loss: 0.5440 - accuracy: 0.7358 - 2s/epoch - 2ms/step\n",
            "Epoch 16/50\n",
            "804/804 - 2s - loss: 0.5445 - accuracy: 0.7360 - 2s/epoch - 3ms/step\n",
            "Epoch 17/50\n",
            "804/804 - 2s - loss: 0.5436 - accuracy: 0.7356 - 2s/epoch - 2ms/step\n",
            "Epoch 18/50\n",
            "804/804 - 2s - loss: 0.5427 - accuracy: 0.7357 - 2s/epoch - 2ms/step\n",
            "Epoch 19/50\n",
            "804/804 - 3s - loss: 0.5438 - accuracy: 0.7366 - 3s/epoch - 3ms/step\n",
            "Epoch 20/50\n",
            "804/804 - 2s - loss: 0.5433 - accuracy: 0.7355 - 2s/epoch - 2ms/step\n",
            "Epoch 21/50\n",
            "804/804 - 2s - loss: 0.5419 - accuracy: 0.7357 - 2s/epoch - 2ms/step\n",
            "Epoch 22/50\n",
            "804/804 - 2s - loss: 0.5421 - accuracy: 0.7363 - 2s/epoch - 2ms/step\n",
            "Epoch 23/50\n",
            "804/804 - 2s - loss: 0.5417 - accuracy: 0.7353 - 2s/epoch - 2ms/step\n",
            "Epoch 24/50\n",
            "804/804 - 2s - loss: 0.5415 - accuracy: 0.7367 - 2s/epoch - 2ms/step\n",
            "Epoch 25/50\n",
            "804/804 - 2s - loss: 0.5418 - accuracy: 0.7360 - 2s/epoch - 2ms/step\n",
            "Epoch 26/50\n",
            "804/804 - 2s - loss: 0.5417 - accuracy: 0.7358 - 2s/epoch - 3ms/step\n",
            "Epoch 27/50\n",
            "804/804 - 2s - loss: 0.5410 - accuracy: 0.7366 - 2s/epoch - 2ms/step\n",
            "Epoch 28/50\n",
            "804/804 - 2s - loss: 0.5404 - accuracy: 0.7372 - 2s/epoch - 2ms/step\n",
            "Epoch 29/50\n",
            "804/804 - 2s - loss: 0.5407 - accuracy: 0.7367 - 2s/epoch - 2ms/step\n",
            "Epoch 30/50\n",
            "804/804 - 2s - loss: 0.5399 - accuracy: 0.7367 - 2s/epoch - 2ms/step\n",
            "Epoch 31/50\n",
            "804/804 - 2s - loss: 0.5405 - accuracy: 0.7370 - 2s/epoch - 2ms/step\n",
            "Epoch 32/50\n",
            "804/804 - 2s - loss: 0.5397 - accuracy: 0.7361 - 2s/epoch - 2ms/step\n",
            "Epoch 33/50\n",
            "804/804 - 2s - loss: 0.5389 - accuracy: 0.7368 - 2s/epoch - 3ms/step\n",
            "Epoch 34/50\n",
            "804/804 - 2s - loss: 0.5394 - accuracy: 0.7365 - 2s/epoch - 2ms/step\n",
            "Epoch 35/50\n",
            "804/804 - 2s - loss: 0.5393 - accuracy: 0.7376 - 2s/epoch - 2ms/step\n",
            "Epoch 36/50\n",
            "804/804 - 2s - loss: 0.5393 - accuracy: 0.7366 - 2s/epoch - 2ms/step\n",
            "Epoch 37/50\n",
            "804/804 - 2s - loss: 0.5391 - accuracy: 0.7368 - 2s/epoch - 2ms/step\n",
            "Epoch 38/50\n",
            "804/804 - 2s - loss: 0.5393 - accuracy: 0.7363 - 2s/epoch - 2ms/step\n",
            "Epoch 39/50\n",
            "804/804 - 2s - loss: 0.5385 - accuracy: 0.7364 - 2s/epoch - 2ms/step\n",
            "Epoch 40/50\n",
            "804/804 - 2s - loss: 0.5379 - accuracy: 0.7377 - 2s/epoch - 2ms/step\n",
            "Epoch 41/50\n",
            "804/804 - 2s - loss: 0.5383 - accuracy: 0.7379 - 2s/epoch - 3ms/step\n",
            "Epoch 42/50\n",
            "804/804 - 2s - loss: 0.5383 - accuracy: 0.7364 - 2s/epoch - 2ms/step\n",
            "Epoch 43/50\n",
            "804/804 - 2s - loss: 0.5375 - accuracy: 0.7367 - 2s/epoch - 2ms/step\n",
            "Epoch 44/50\n",
            "804/804 - 2s - loss: 0.5375 - accuracy: 0.7376 - 2s/epoch - 2ms/step\n",
            "Epoch 45/50\n",
            "804/804 - 2s - loss: 0.5371 - accuracy: 0.7373 - 2s/epoch - 2ms/step\n",
            "Epoch 46/50\n",
            "804/804 - 2s - loss: 0.5376 - accuracy: 0.7381 - 2s/epoch - 2ms/step\n",
            "Epoch 47/50\n",
            "804/804 - 2s - loss: 0.5377 - accuracy: 0.7378 - 2s/epoch - 2ms/step\n",
            "Epoch 48/50\n",
            "804/804 - 3s - loss: 0.5372 - accuracy: 0.7379 - 3s/epoch - 3ms/step\n",
            "Epoch 49/50\n",
            "804/804 - 2s - loss: 0.5377 - accuracy: 0.7380 - 2s/epoch - 2ms/step\n",
            "Epoch 50/50\n",
            "804/804 - 2s - loss: 0.5372 - accuracy: 0.7383 - 2s/epoch - 2ms/step\n",
            "268/268 - 0s - loss: 0.5574 - accuracy: 0.7289 - 491ms/epoch - 2ms/step\n",
            "Loss: 0.5573607087135315, Accuracy: 0.728863000869751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U7hv-LAdJkIl"
      },
      "outputs": [],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save(\"AlphabetSoupCharity_Optimization.h5\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.-1.-1"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}